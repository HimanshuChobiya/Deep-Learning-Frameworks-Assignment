{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Deep Learning Frameworks\n"
      ],
      "metadata": {
        "id": "I79Pq2B2fkuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.1. What is TensorFlow 2.0, and how is it different from TensorFlow 1.x?\n",
        "\n",
        "-->TensorFlow 2.0 is a major version of the TensorFlow deep learning library focused on ease-of-use, eager execution, and tighter Keras integration. Differences vs 1.x:\n",
        "\n",
        "Eager execution enabled by default in TF2: code runs imperatively (like NumPy), improving debuggability. TF1.x used graph-building by default.\n",
        "\n",
        "Keras as the high-level API: tf.keras is the recommended model-building interface.\n",
        "\n",
        "Cleaner and smaller API: many legacy APIs and symbols removed or moved to tf.compat.\n",
        "\n",
        "Simpler deployment & autograph: tf.function and AutoGraph convert Python to graph as needed.\n",
        "\n",
        "Better user experience with unified workflows for training, saving and serving."
      ],
      "metadata": {
        "id": "7MpbqFwyfoZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.3. How do you install TensorFlow 2.0?\n",
        "\n",
        "###Answer:\n",
        "Install via pip (example for CPU):"
      ],
      "metadata": {
        "id": "xYIGmBrHf3Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.0.0\n"
      ],
      "metadata": {
        "id": "EMGpRpplgJU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the latest TF2.x just:"
      ],
      "metadata": {
        "id": "oiGLaGXigEae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "id": "4NcOdQCzgDMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For GPU-enabled builds, install tensorflow (TF 2.1+ unified GPU/CPU package) or pip install tensorflow-gpu==2.0.0 for older versions, plus CUDA/cuDNN versions that match TF’s requirements. Verify via:"
      ],
      "metadata": {
        "id": "hzrfHqY_gTsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "jcb_FNKDgVCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.3.What is the primary function of the tf.function in TensorFlow 2.0?\n",
        "\n",
        "-->> tf.function transforms a Python function into a TensorFlow graph (a callable ConcreteFunction) using AutoGraph. This gives performance benefits (graph optimizations, faster execution) while allowing you to write idiomatic Python. Use @tf.function to get graph-mode speed for production while keeping eager-mode debugging during development."
      ],
      "metadata": {
        "id": "tIYeyOvHgXfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.4. What is the purpose of the Model class in TensorFlow 2.0?\n",
        "\n",
        "-->The tf.keras.Model class is the core high-level abstraction for building models. It:\n",
        "\n",
        "Encapsulates layers, forward pass (call()), training/evaluation logic and weights.\n",
        "\n",
        "Provides methods like compile(), fit(), evaluate(), predict(), save().\n",
        "\n",
        "Can be subclassed to define custom models with custom call() behavior."
      ],
      "metadata": {
        "id": "dXH-wJjygdbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.5. How do you create a neural network using TensorFlow 2.0?\n",
        "\n",
        "-->>\n",
        "1. Sequential API (simple stack):"
      ],
      "metadata": {
        "id": "uWZn5U-agkN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(input_dim,)),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "id": "Xm86WkE3gr1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Functional API (complex graphs):"
      ],
      "metadata": {
        "id": "J4sI4NpLgu4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Input, Model\n",
        "x = Input(shape=(input_dim,))\n",
        "h = Dense(64, activation='relu')(x)\n",
        "out = Dense(10, activation='softmax')(h)\n",
        "model = Model(inputs=x, outputs=out)\n"
      ],
      "metadata": {
        "id": "jB7AjcJ0gvmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Subclassing tf.keras.Model (custom behavior):"
      ],
      "metadata": {
        "id": "eTSIM3p_gzoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.d1 = Dense(64, activation='relu')\n",
        "        self.out = Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.d1(inputs)\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "xD8lA9Nvg1a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.6.What is the importance of Tensor (Tensor Space) in TensorFlow?\n",
        "\n",
        "-->>A tensor is a multi-dimensional array (generalization of scalars, vectors, matrices). Tensors are the basic units of data in TensorFlow and carry values with dtype and shape. Tensor space (the set of tensors) enables:\n",
        "\n",
        "Representation of inputs, weights, activations, gradients.\n",
        "\n",
        "Efficient computation on CPU/GPU/TPU.\n",
        "\n",
        "Automatic differentiation (tape) on operations composed from tensors."
      ],
      "metadata": {
        "id": "cE_b6NIkg6d0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.7. How can TensorBoard be integrated with TensorFlow 2.0?\n",
        "\n",
        "-->>Integration steps:\n",
        "\n",
        "Create a tf.summary.create_file_writer(log_dir).\n",
        "\n",
        "During training or evaluation, write scalars, histograms, images using tf.summary.scalar(), tf.summary.histogram(), etc. inside the writer context.\n",
        "\n",
        "If using model.fit(), pass TensorBoard callback:"
      ],
      "metadata": {
        "id": "94ACWIzihDNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "tb = TensorBoard(log_dir='logs/run1')\n",
        "model.fit(x, y, epochs=..., callbacks=[tb])\n"
      ],
      "metadata": {
        "id": "97Ue8hEQg5_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.8. What is the purpose of TensorFlow Playground?\n",
        "\n",
        "-->> TensorFlow Playground is an interactive web-based visualization that helps users learn how neural networks behave (activation functions, layers, learning rate, regularization, etc.) using small synthetic datasets. It's educational — great for intuition but not for production.\n"
      ],
      "metadata": {
        "id": "-4mRe1xwhJqV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.9. What is Netron, and how is it useful for deep learning models?\n",
        "\n",
        "-->> Netron is a visualizer for neural network, ONNX, TensorFlow, Keras, PyTorch, Core ML and other model formats. It helps inspect layer-by-layer structure, shapes, and parameters — useful for debugging model architecture, sharing models, and verifying exported models."
      ],
      "metadata": {
        "id": "aSSAD1XVhN24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.10. What is the difference between TensorFlow and PyTorch?\n",
        "\n",
        "-->> Key differences:\n",
        "\n",
        "Execution model: TF2 uses eager execution by default (TF1 used graphs); PyTorch uses eager execution (dynamic graphs) by default — both support graph compilation (tf.function, TorchScript).\n",
        "\n",
        "API style: PyTorch is more “Pythonic” and widely favored in research; TensorFlow (with tf.keras) targets production and ecosystem (TensorBoard, TF Serving).\n",
        "\n",
        "Deployment: TensorFlow has long-established production tooling (TF Serving, TF Lite, TF.js). PyTorch has improved (TorchServe, torchscript) but TF historically had broader production ecosystem.\n",
        "\n",
        "Community & adoption: Both large; PyTorch gained rapid research adoption; TF widely used in industry and has robust ecosystem."
      ],
      "metadata": {
        "id": "_638MaWThUj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.11. How do you install PyTorch?\n",
        "\n",
        "-->> Installation varies by OS, Python and CUDA. Common command (CPU only):\n",
        "\n",
        "pip install torch torchvision"
      ],
      "metadata": {
        "id": "-lI0PabLhZJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.12. What is the basic structure of a PyTorch neural network?\n",
        "\n",
        "-->> In PyTorch you define a subclass of torch.nn.Module:"
      ],
      "metadata": {
        "id": "DQMp0WZmhpik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nW-3liRRhYni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.13. What is the significance of tensors in PyTorch?\n",
        "\n",
        "-->>Tensors are the primary data structure in PyTorch (similar to NumPy arrays) but with GPU acceleration and autograd support. They hold data and gradients, and operations on tensors are tracked for automatic differentiation."
      ],
      "metadata": {
        "id": "SuFJXUsJhicA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.14. What is the difference between torch.Tensor and torch.cuda.Tensor in PyTorch?\n",
        "\n",
        "-->> torch.Tensor is a CPU tensor by default; torch.cuda.Tensor (or tensor.to('cuda')) is stored on the GPU. GPU tensors allow CUDA-accelerated operations. API differences are mostly about device placement; operations across devices require explicit transfers."
      ],
      "metadata": {
        "id": "W1riUri7h51y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.15. What is the purpose of the torch.optim module in PyTorch?\n",
        "\n",
        "-->>\n",
        "torch.optim provides optimization algorithms (SGD, Adam, RMSprop, etc.) that update model parameters based on computed gradients. You create an optimizer with model parameters and learning hyperparameters, then call optimizer.step() after loss.backward()."
      ],
      "metadata": {
        "id": "gStTEfjJh_mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.16. What are some common activation functions used in neural networks?\n",
        "\n",
        "-->>\n",
        "\n",
        "ReLU (Rectified Linear Unit)\n",
        "\n",
        "Sigmoid\n",
        "\n",
        "Tanh\n",
        "\n",
        "Leaky ReLU / Parametric ReLU\n",
        "\n",
        "Softmax (for multi-class output)\n",
        "\n",
        "ELU, SELU, Swish (modern alternatives)"
      ],
      "metadata": {
        "id": "ESi5mK8AiGan"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.17. What is the difference between torch.nn.Module and torch.nn.Sequential in PyTorch?\n",
        "\n",
        "-->>\n",
        "\n",
        "torch.nn.Module: Base class for all models—used for flexible, custom forward logic.\n",
        "\n",
        "torch.nn.Sequential: A simple container for stacking layers in order; best when model is purely feed-forward with no branching or custom control flow. Sequential is a convenience wrapper around Module."
      ],
      "metadata": {
        "id": "Dkq103q9iNOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.18. How can you monitor training progress in TensorFlow 2.0?\n",
        "\n",
        "-->>\n",
        "\n",
        "Use model.fit() and monitor metrics it prints.\n",
        "\n",
        "Use callbacks: TensorBoard for visual logs, ModelCheckpoint for saving, EarlyStopping for stopping on plateau.\n",
        "\n",
        "Log metrics with tf.summary during custom loops.\n",
        "\n",
        "Plot loss/accuracy with Matplotlib after training."
      ],
      "metadata": {
        "id": "ZGGtHyhBiTLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.19. How does the Keras API fit into TensorFlow 2.0?\n",
        "\n",
        "-->>\n",
        "\n",
        "Keras (tf.keras) is the high-level API integrated into TF2 and is the recommended interface for building and training models. It provides Layer, Model, Sequential, compile, fit, and callbacks — simplifying model development while leveraging TensorFlow’s runtime and tools."
      ],
      "metadata": {
        "id": "MsQjeUfxiWao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.20. What is an example of a deep learning project that can be implemented using TensorFlow 2.0?\n",
        "\n",
        "-->>(examples):\n",
        "\n",
        "Image classification with CNNs (e.g., CIFAR-10).\n",
        "\n",
        "Object detection (using TensorFlow Object Detection API).\n",
        "\n",
        "Time-series forecasting using LSTM/Transformer.\n",
        "\n",
        "NLP tasks with Transformers (fine-tune BERT via transformers + TF).\n",
        "\n",
        "Generative models (GANs, VAEs)."
      ],
      "metadata": {
        "id": "AhzUaxsPiaye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.21. What is the main advantage of using pre-trained models in TensorFlow and PyTorch?\n",
        "\n",
        "-->>\n",
        "Pre-trained models provide transfer learning advantages: faster convergence, significantly reduced training time and data requirements, and often better performance — especially when data is limited. They let you fine-tune high-quality feature extractors for downstream tasks."
      ],
      "metadata": {
        "id": "LnCboIbvifLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "0UKxdBJQimGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.1. How do you install and verify that TensorFlow 2.0 was installed successfully?"
      ],
      "metadata": {
        "id": "pFnCcb7WiquP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# Optionally check eager mode\n",
        "print(tf.executing_eagerly())\n"
      ],
      "metadata": {
        "id": "wVGvjnLYh3QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.2. How can you define a simple function in TensorFlow 2.0 to perform addition?"
      ],
      "metadata": {
        "id": "OhJq8I7uiupI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def add(a, b):\n",
        "    return tf.add(a, b)\n",
        "\n",
        "# As graph:\n",
        "@tf.function\n",
        "def add_graph(a, b):\n",
        "    return a + b\n"
      ],
      "metadata": {
        "id": "Htebuc2ni7rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.3. How can you create a simple neural network in TensorFlow 2.0 with one hidden layer?"
      ],
      "metadata": {
        "id": "g-VnKsKAi_i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inp = Input(shape=(input_dim,))\n",
        "h = Dense(32, activation='relu')(inp)\n",
        "out = Dense(num_classes, activation='softmax')(h)\n",
        "model = Model(inp, out)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "6f4z_TJLjKFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.4. How can you visualize the training progress using TensorFlow and Matplotlib?"
      ],
      "metadata": {
        "id": "FXOcZ-NvjUay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(...)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','val'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dxk-eKzHjW3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.5. How do you install PyTorch and verify the PyTorch installation?"
      ],
      "metadata": {
        "id": "mL1S6L_ZjcwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())\n"
      ],
      "metadata": {
        "id": "7kVggRp0jd5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.6. How do you create a simple neural network in PyTorch?"
      ],
      "metadata": {
        "id": "kvs02DqnjhIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "IWHC11iHjiQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.7.How do you define a loss function and optimizer in PyTorch?"
      ],
      "metadata": {
        "id": "nQlZ9bmMjkbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "model = SimpleNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
      ],
      "metadata": {
        "id": "P-F4uSxCjnBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.8. How do you implement a custom loss function in PyTorch?"
      ],
      "metadata": {
        "id": "b6wFLXeujqOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "\n",
        "        return torch.mean(torch.abs((targets - outputs) / (targets + 1e-8)))\n"
      ],
      "metadata": {
        "id": "7vbL3DywjrOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q.9. How do you save and load a TensorFlow model?"
      ],
      "metadata": {
        "id": "CAme0TcnjvfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('path/to/saved_model')\n",
        "loaded = tf.keras.models.load_model('path/to/saved_model')\n"
      ],
      "metadata": {
        "id": "KL-CtjrujwxY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}